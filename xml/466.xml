<bug>
          <bug_id>466</bug_id>
          
          <creation_ts>2007-06-04 21:20:00 +0200</creation_ts>
          <short_desc>Multiple RequestQueues</short_desc>
          <delta_ts>2007-06-28 11:46:02 +0200</delta_ts>
          <reporter_accessible>1</reporter_accessible>
          <cclist_accessible>1</cclist_accessible>
          <classification_id>1</classification_id>
          <classification>Unclassified</classification>
          <product>framework</product>
          <component>core.io</component>
          <version>master</version>
          <rep_platform>All</rep_platform>
          <op_sys>All</op_sys>
          <bug_status>RESOLVED</bug_status>
          <resolution>WONTFIX</resolution>
          
          
          
          
          
          <priority>P3</priority>
          <bug_severity>enhancement</bug_severity>
          <target_milestone>unspecified</target_milestone>
          
          
          
          <everconfirmed>1</everconfirmed>
          <reporter name="Rüdiger Herrmann">rherrmann</reporter>
          <assigned_to name="Unassigned">none</assigned_to>
          
          <qa_contact name="qooxdoo bugs mailing list">qooxdoo-bugs</qa_contact>
          <cf_browser>---</cf_browser>
          

      

      

      

          <long_desc isprivate="0">
            <commentid>1503</commentid>
            <who name="Rüdiger Herrmann">rherrmann</who>
            <bug_when>2007-06-04 21:20:16 +0200</bug_when>
            <thetext>The qx.io.remote.RequestQueue currently does only allow one instance. I would be desirable to create arbitrary RequestQueues and be able to decide on which queue a request should be sent.

In our scenario we have two kinds of requests:
- a &#39;normal&#39; request, only one request at a time should be running, more than one concurrent request could break the client-side application
- a so called &#39;UI callback&#39; request that is independent of the &#39;normal&#39; request. There could theoretically be more than one concurrent request - though in our case the server ensures that there is only only request at a time.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>1504</commentid>
              <attachid>180</attachid>
            <who name="Rüdiger Herrmann">rherrmann</who>
            <bug_when>2007-06-04 21:27:29 +0200</bug_when>
            <thetext>Created attachment 180
The patch shows the intended enhancement

Please note that this patch is untested and I am by no means a JavaScript expert. This attachment is rather to meant to clarify the desired enhancement.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>1694</commentid>
            <who name="Sebastian Werner">info</who>
            <bug_when>2007-06-28 11:46:02 +0200</bug_when>
            <thetext>I would say that this controlling should be on top of the normal request/queue system and not integrated into it. The IO system itself should be quite basic. All other, more advanced, management features should sit on-top of this low level implementation.</thetext>
          </long_desc>
      
          <attachment isobsolete="0" ispatch="0" isprivate="0" isurl="0">
            <attachid>180</attachid>
            <date>2007-06-04 21:27:00 +0200</date>
            <delta_ts>2007-06-04 21:27:29 +0200</delta_ts>
            <desc>The patch shows the intended enhancement</desc>
            <filename>Request.js.patch</filename>
            <type>application/octet-stream</type>
            <size>1179</size>
            <attacher>rherrmann</attacher>
            
              <data encoding="base64">SW5kZXg6IC4NCj09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09PT09
PT09PT09PT09PT09PT09PT09PT0NCi0tLSAuCShyZXZpc2lvbiA4Mzg0KQ0KKysrIC4JKHdvcmtp
bmcgY29weSkNCkBAIC01Miw3ICs1Miw3IEBADQogICAgKiBAcGFyYW0gdlJlc3BvbnNlVHlwZSB7
U3RyaW5nfQogICAgKiAgIFRoZSBtaW1lIHR5cGUgb2YgdGhlIHJlc3BvbnNlLiBEZWZhdWx0IGlz
IHRleHQvcGxhaW4ge0BsaW5rIHF4LnV0aWwuTWltZX0uCiAgICAqLwotICBjb25zdHJ1Y3QgOiBm
dW5jdGlvbih2VXJsLCB2TWV0aG9kLCB2UmVzcG9uc2VUeXBlKQorICBjb25zdHJ1Y3QgOiBmdW5j
dGlvbih2VXJsLCB2TWV0aG9kLCB2UmVzcG9uc2VUeXBlLCB2UmVxdWVzdFF1ZXVlKQogICB7CiAg
ICAgdGhpcy5iYXNlKGFyZ3VtZW50cyk7CiAKQEAgLTcxLDcgKzcxLDEzIEBADQogICAgIGlmICh2
UmVzcG9uc2VUeXBlICE9PSB1bmRlZmluZWQpIHsKICAgICAgIHRoaXMuc2V0UmVzcG9uc2VUeXBl
KHZSZXNwb25zZVR5cGUpOwogICAgIH0KLQorICAgIAorICAgIGlmICh2UmVxdWVzdFF1ZXVlICE9
PSB1bmRlZmluZWQpIHsKKyAgICAgIHRoaXMuX3JlcXVlc3RRdWV1ZSA9IHZSZXF1ZXN0UXVldWU7
IAorICAgIH0gZWxzZSB7CisgICAgICB0aGlzLl9yZXF1ZXN0UXVldWUgPSBxeC5pby5yZW1vdGUu
UmVxdWVzdFF1ZXVlLmdldEluc3RhbmNlKCk7CisgICAgfQorICAgIAogICAgIHRoaXMuc2V0UHJv
aGliaXRDYWNoaW5nKHRydWUpOwogCiAgICAgLy8gUHJvdG90eXBlLVN0eWxlIFJlcXVlc3QgSGVh
ZGVycwpAQCAtMzU1LDcgKzM2MSw3IEBADQogICAgICAqIEByZXR1cm4ge3ZvaWR9CiAgICAgICov
CiAgICAgc2VuZCA6IGZ1bmN0aW9uKCkgewotICAgICAgcXguaW8ucmVtb3RlLlJlcXVlc3RRdWV1
ZS5nZXRJbnN0YW5jZSgpLmFkZCh0aGlzKTsKKyAgICAgIHRoaXMuX3JlcXVlc3RRdWV1ZS5hZGQo
dGhpcyk7CiAgICAgfSwKIAogCkBAIC0zNzAsNyArMzc2LDcgQEANCiAgICAgICogQHJldHVybiB7
dm9pZH0KICAgICAgKi8KICAgICBhYm9ydCA6IGZ1bmN0aW9uKCkgewotICAgICAgcXguaW8ucmVt
b3RlLlJlcXVlc3RRdWV1ZS5nZXRJbnN0YW5jZSgpLmFib3J0KHRoaXMpOworICAgICAgdGhpcy5f
cmVxdWVzdFF1ZXVlLi5hYm9ydCh0aGlzKTsKICAgICB9LAogCiAK
</data>

          </attachment>
      

    </bug>
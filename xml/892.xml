<bug>
          <bug_id>892</bug_id>
          
          <creation_ts>2008-05-30 11:44:00 +0200</creation_ts>
          <short_desc>tokenizer chokes on divison</short_desc>
          <delta_ts>2008-06-05 14:29:23 +0200</delta_ts>
          <reporter_accessible>1</reporter_accessible>
          <cclist_accessible>1</cclist_accessible>
          <classification_id>1</classification_id>
          <classification>Unclassified</classification>
          <product>framework</product>
          <component>tool.generator</component>
          <version>unspecified</version>
          <rep_platform>All</rep_platform>
          <op_sys>All</op_sys>
          <bug_status>RESOLVED</bug_status>
          <resolution>FIXED</resolution>
          
          
          
          
          
          <priority>P3</priority>
          <bug_severity>normal</bug_severity>
          <target_milestone>unspecified</target_milestone>
          
          
          
          <everconfirmed>1</everconfirmed>
          <reporter name="Thomas Herchenroeder">thron7</reporter>
          <assigned_to name="Thomas Herchenroeder">thron7</assigned_to>
          
          <qa_contact name="qooxdoo bugs mailing list">qooxdoo-bugs</qa_contact>
          <cf_browser>---</cf_browser>
          

      

      

      

          <long_desc isprivate="0">
            <commentid>3111</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2008-05-30 11:44:57 +0200</bug_when>
            <thetext>Tobi Oetiker reports:

I just moved some code written for 0.7.2 up to the latest 0.7.x.

It seems java script tokeizer has been modified ...

the 0.7.2 version was happy with the line
               drow[f_stdev] = 1.0/cnt*(sqsum-sum*sum/cnt);

while the 0.7svn tokenizer only accepts the following
               drow[f_stdev] = 1.0/cnt*(sqsum-sum*sum /cnt);


The rather unenlightning error from the parser is quoted below.
let me know if you need more information.

  * Resolving dependencies: .........................................................................................................................................................................................................................................................................................................................................................................................................................................................................Traceback (most recent call last):
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/generator.py&quot;, line 1263, in ?
    main()
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/generator.py&quot;, line 325, in main
    argparser(sys.argv[1:])
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/generator.py&quot;, line 308, in argparser
    (fileDb, moduleDb) = load(options)
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/generator.py&quot;, line 350, in load
    (fileDb, moduleDb) = loader.indexAll(options)
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/modules/loader.py&quot;, line 616, in indexAll
    resolveAutoDeps(fileDb, options)
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/modules/loader.py&quot;, line 364, in resolveAutoDeps
    detectDeps(getTree(fileDb, fileId, options), fileEntry[&quot;optionalDeps&quot;], loadtimeDeps, runtimeDeps, fileId, fileDb, False)
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/modules/loader.py&quot;, line 274, in getTree
    tree = treegenerator.createSyntaxTree(getTokens(fileDb, fileId, options))
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/modules/loader.py&quot;, line 238, in getTokens
    tokens = tokenizer.parseStream(fileContent, fileId)
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/modules/tokenizer.py&quot;, line 343, in parseStream
    content = parseFragmentLead(content, fragment, tokens)
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/modules/tokenizer.py&quot;, line 241, in parseFragmentLead
    tokens.extend(parsePart(recoverEscape(content[0:pos])))
  File &quot;/usr/pack/qooxdoo-0.7svn-to/frontend/framework/tool/modules/tokenizer.py&quot;, line 190, in parsePart
    if (    (tokens[-1][&#39;detail&#39;] != &#39;int&#39;)   and
IndexError: list index out of range
make: *** [exec-script-source] Error 1</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>3118</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2008-05-30 12:35:44 +0200</bug_when>
            <thetext>fixed in 0_7_*/trunk with r13765</thetext>
          </long_desc>
      
      

    </bug>
<bug>
          <bug_id>1994</bug_id>
          
          <creation_ts>2009-02-25 10:34:00 +0100</creation_ts>
          <short_desc>Define a way for tests to specify requirements</short_desc>
          <delta_ts>2014-03-03 15:26:32 +0100</delta_ts>
          <reporter_accessible>1</reporter_accessible>
          <cclist_accessible>1</cclist_accessible>
          <classification_id>1</classification_id>
          <classification>Unclassified</classification>
          <product>framework</product>
          <component>app.testrunner</component>
          <version>unspecified</version>
          <rep_platform>All</rep_platform>
          <op_sys>All</op_sys>
          <bug_status>CLOSED</bug_status>
          <resolution>FIXED</resolution>
          
          
          
          
          
          <priority>P2</priority>
          <bug_severity>enhancement</bug_severity>
          <target_milestone>1.3</target_milestone>
          <dependson>3798</dependson>
    
    <dependson>3954</dependson>
          
          
          <everconfirmed>1</everconfirmed>
          <reporter name="Daniel Wagner">daniel.wagner</reporter>
          <assigned_to name="Daniel Wagner">daniel.wagner</assigned_to>
          <cc>christian.hagendorn</cc>
    
    <cc>martin.wittemann</cc>
          <qa_contact name="qooxdoo bugs mailing list">qooxdoo-bugs</qa_contact>
          <cf_browser>---</cf_browser>
          

      

      

      

          <long_desc isprivate="0">
            <commentid>8022</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2009-02-25 10:34:22 +0100</bug_when>
            <thetext>Some unit tests may require a certain environment, such as a web server to avoid same origin policy issues or a specific browser. There should be a way to define such requirements in a test so that the Test Runner can skip them if they are not met (while still informing the user that a test was skipped, and why).</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>10110</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2009-05-25 18:16:19 +0200</bug_when>
            <thetext>Chris and I had a brief discussion about this topic, here&#39;s the summary:

There are two use cases for test requirements:
1) Infrastructure requirements
  Examples: Google Gears installed, Flash plugin available
  These requirements could be configured in the test class. The Test Runner would then be responsible for the actual check and mark the test as invalid if the requirement isn&#39;t met.
  Question: Should the check be performed before or after the test class&#39; setUp method?

2) Runtime requirements
	Example: Was a Flash object initialized correctly?
	These requirements should be checked in the test method itself. If they&#39;re not met, the test should report itself as invalid to the Test Runner.
	
Invalid tests should be colored yellow in the results pane. The amount of invalid tests should be listed next to the amounts of failed/successful tests.

In the automated test reports, it wouldn&#39;t be necessary to explicitly list all invalid tests since some requirements (like the Flash object initialization mentioned under 2) will never be met in the automated test environment. Instead, only the amount of invalid tests should be reported.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>10111</commentid>
            <who name="Andreas Ecker">qooxdoo</who>
            <bug_when>2009-05-25 19:54:28 +0200</bug_when>
            <thetext>I don&#39;t get it for #2 (Runtime requirements). Could you explain why that shouldn&#39;t just be a regular test failure?
</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>10115</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2009-05-26 08:52:48 +0200</bug_when>
            <thetext>In that example, the test is trying to communicate with the Flash object which will fail in some browsers if the window is minimized (or during automated test runs). So the actual test didn&#39;t fail, it just couldn&#39;t be run.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>12239</commentid>
            <who name="Andreas Ecker">qooxdoo</who>
            <bug_when>2009-09-14 10:54:04 +0200</bug_when>
            <thetext>marked as enhancement with high prio for next release</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>13149</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2009-10-13 10:48:43 +0200</bug_when>
            <thetext>Here&#39;s a blog post on Assumptions, JUnit&#39;s way of defining requirements:
http://eclipsesource.com/blogs/2009/10/07/using-junits-assume-for-faster-tests/</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>14743</commentid>
            <who name="Andreas Ecker">qooxdoo</who>
            <bug_when>2009-11-24 20:26:03 +0100</bug_when>
            <thetext>mass renaming of 0.9 target to 1.0 (for issues with status &quot;NEW&quot;)</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>15676</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2009-12-11 10:09:15 +0100</bug_when>
            <thetext>Out of 1.0 timeframe - moved to 1.0.1</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>16495</commentid>
            <who name="Andreas Ecker">qooxdoo</who>
            <bug_when>2010-01-27 16:30:47 +0100</bug_when>
            <thetext>moved to target 1.0.2</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>19362</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2010-07-16 14:57:59 +0200</bug_when>
            <thetext>*** Bug 3798 has been marked as a duplicate of this bug. ***</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>19445</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2010-07-27 17:19:00 +0200</bug_when>
            <thetext>Moved again due to lack of time :(</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>21238</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2010-11-11 14:52:18 +0100</bug_when>
            <thetext>Test classes can now include a new mixin, qx.dev.unit.MRequirements. Requirements can then be defined by calling this.require from test functions. require takes a list of requirement IDs, e.g. &quot;ssl&quot; and looks for corresponding &quot;has&quot; methods, in this case &quot;hasSsl&quot;. These methods could be included from the mixin or defined as members of the test class.

If such a method is not found on the test class instance, an exception &quot;Unable to verify requirement&quot; is thrown, otherwise, the &quot;has&quot; method is called. If it returns false, a qx.dev.unit.RequirementError is thrown and any test code following the require call is not executed.

The new testrunner2 visually marks tests with a RequirementError as &quot;skipped&quot; and keeps counts of passed, failed and skipped tests. The standard testrunner will treat skipped tests like failed tests.

Still to do: Identify some common environment requirements and add corresponding &quot;has&quot; methods to MRequirements. So far, there&#39;s only &quot;hasSsl&quot; and &quot;hasHttp&quot;.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>21271</commentid>
            <who name="Martin Wittemann">martin.wittemann</who>
            <bug_when>2010-11-15 09:24:52 +0100</bug_when>
            <thetext>Here is a list what I can think of:

- hasPHP

- hasTouch

- hasIE
- hasFirefox
- hasChrome
- hasOpera
- hasWebkit

- hasGUIApp
- hasInlineApp
- hasNativeApp
- hasBomApp</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>21455</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2010-11-22 11:21:47 +0100</bug_when>
            <thetext>Added the following checks in r23902:

GuiApp
InlineApp
NativeApp
Touch
Flash
Chrome
Firefox
Gecko
IE
MSHTML
Opera
Webkit

We can&#39;t check for BOM applications since they don&#39;t implement qx.application.IApplication which means there&#39;s not TestLoader for them - so the AUT can never be a BOM app.

Checking for PHP is something we can&#39;t do in a generic way since it involves making a backend request with a URI we don&#39;t know in advance. Going to have to leave this up to the test developer.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>21461</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2010-11-22 13:56:45 +0100</bug_when>
            <thetext>Chris suggested a way to check for PHP: Similar to the XmlHttp tests, we can use a PHP script that is defined as a resource.
Added hasPHP in r23906.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>21482</commentid>
            <who name="Martin Wittemann">martin.wittemann</who>
            <bug_when>2010-11-23 08:51:29 +0100</bug_when>
            <thetext>Sounds good. Do you plan to add some more or are we done with that?</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>21487</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2010-11-23 09:14:07 +0100</bug_when>
            <thetext>Unless someone suggests another useful addition, all that&#39;s left is to document the new feature.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>21705</commentid>
            <who name="Daniel Wagner">daniel.wagner</who>
            <bug_when>2010-12-02 16:12:31 +0100</bug_when>
            <thetext>Added documentation in r24105.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>39146</commentid>
            <who name="Martin Wittemann">martin.wittemann</who>
            <bug_when>2014-03-03 15:26:32 +0100</bug_when>
            <thetext>Closed all bugs already shipped with a release.</thetext>
          </long_desc>
      
      

    </bug>
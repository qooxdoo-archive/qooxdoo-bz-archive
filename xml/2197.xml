<bug>
          <bug_id>2197</bug_id>
          
          <creation_ts>2009-04-03 09:33:00 +0200</creation_ts>
          <short_desc>Provide Environment for automated Tool Tests</short_desc>
          <delta_ts>2014-03-03 08:45:57 +0100</delta_ts>
          <reporter_accessible>1</reporter_accessible>
          <cclist_accessible>1</cclist_accessible>
          <classification_id>1</classification_id>
          <classification>Unclassified</classification>
          <product>framework</product>
          <component>tool</component>
          <version>0.8.2</version>
          <rep_platform>All</rep_platform>
          <op_sys>All</op_sys>
          <bug_status>RESOLVED</bug_status>
          <resolution>LATER</resolution>
          
          
          
          
          
          <priority>P3</priority>
          <bug_severity>enhancement</bug_severity>
          <target_milestone>unspecified</target_milestone>
          <dependson>3657</dependson>
    
    <dependson>3658</dependson>
          
          
          <everconfirmed>1</everconfirmed>
          <reporter name="Thomas Herchenroeder">thron7</reporter>
          <assigned_to name="Richard Sternagel">richard.sternagel</assigned_to>
          <cc>thron7</cc>
          <qa_contact name="Richard Sternagel">richard.sternagel</qa_contact>
          <cf_browser>---</cf_browser>
          

      

      

      

          <long_desc isprivate="0">
            <commentid>9109</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2009-04-03 09:33:58 +0200</bug_when>
            <thetext>Provide an environment for automated tool testing. The main target for this 
environment is the generator. The environment should provide an easy way to 
execute the tests, and at the same time be easily extensible so that it can 
accommodate a large body of tool tests. It should be straight-forward for 
developers to add tests. The aim of the tests is functional correctness of the 
tool under test, and a high degree of code coverage should eventually be 
achieved.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>9111</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2009-04-03 10:35:13 +0200</bug_when>
            <thetext>This goes in the direction of unit testing, where &#39;unit&#39; is taken less narrow. 
It seems too demanding to really create tests for each Python module (currently 
70+), although that would be in the true spirit of unit testing and might be a 
longer term goal for the test environment.

For near term results, it seems more appropriate to test higher-level &#39;units&#39;, 
a more coarse partitioning of a tool&#39;s functionality. For the generator this 
might be:

- compiler
- config system
- cache
- pretty printer

A big subsystem like the compiler might be easily broken down in further parts 
that deserve to be regarded as separate units in this sense. So it is about a 
high-level, functional decomposition of the generator, to come up with the main 
building blocks that can be reasonably tested individually.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>9112</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2009-04-03 10:43:02 +0200</bug_when>
            <thetext>General test strategy for generator units

A test of such a high-level unit, which necessarily subsumes several modules 
underneath, has a lot of characteristics of end-to-end integration testing. For 
the generator, this will in many cases follow the scheme of handling three 
types of test data:

- input data (like a JS source code file)
- output data (what the generator produced)
- reference data (to be compared with the output data, to automatically test 
correctness)

This also means that a lot of effort will be going into producing and 
*maintaining* input and reference data for each test. For 30 tests of this kind 
this would amount to 60 files, which have to be written (input data), generated 
(reference data), checked for correctness (reference data), and re-checked and 
potentially adapted  after changes to the tool code base (again reference 
data). And 30 is very likely grossly underestimated.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>9113</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2009-04-03 10:45:12 +0200</bug_when>
            <thetext>Comparing data

This brings us to another issue in this specific context: comparing the output 
with the reference data. For many cases this will probably mean compare 
sequential text (e.g. two files containing JS source code). In some cases white 
space will matter (e.g. when checking the output of a pretty-print run). In 
others, white space will not be significant and has to be ignored by the 
comparison. The standard Unix utility &#39;diff&#39; is not really suitable for those 
tests. Although it has a &#39;-w&#39; flag to ignore all white space, this actually 
doesn&#39;t work in the expected way in my experience.

I have therefore long ago developed a script that really ignores differences in 
white space (blanks, tabs, newlines, ...) and only compares the sequence of 
tokens of two files. This script has to be adapted and integrated into the test 
environment.</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>9124</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2009-04-03 12:43:59 +0200</bug_when>
            <thetext>Bugs integration

A further idea would be integration with qooxdoo-contrib/Bugs. Many bugs 
provide excellent test data in their corresponding qooxdoo-contrib/Bugs folder. 
The test suite could leverage this data so that test data serves automatically 
as test cases. In order to achieve this, the test suite has to:

- find relevant bugs; this could be provided as a list of bug numbers.
- make sense of the test data contained in specific bug (e.g. how to use test 
files as input for generator runs, options to apply, etc.); this could be 
achieved by comments in the data files, or a &#39;unittest&#39; job in a config.json 
file they have to provide (probably the better idea).
- find reference data in the bug folder; this means reference data has to be 
provided there, and in a unified way (e.g. as *.ref.* files, or a reference/ 
subfolder).</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>17461</commentid>
            <who name="Thomas Herchenroeder">thron7</who>
            <bug_when>2010-03-23 12:44:51 +0100</bug_when>
            <thetext>Run test jobs

Another approach - now implemented - is to provide an app and a config with 
test jobs. These test jobs are to exercise the default jobs (as documented in 
the wiki [1], minus the build jobs &#39;source&#39; and &#39;build&#39;, which are run with the 
application tests anyway), and as much of the available config keys [2] as 
possible. The simplest test is just to recognize that the jobs run without 
raising an exception and the generator returns 0 as its shell exit. (As most 
jobs generate data, either on STDOUT or on the file system, this data could be 
compared against reference data. But this is a future step, as it requires a 
much more elaborate test setup).

An initial version is currently implemented using Feedreader as the test app 
(Maybe one day there has to be a dedicated test app to replace it). The 
configuration with the test jobs is 
tool/test/config/default_jobs_and_keys/config.json. Run the tests by chdir to 
application/feedreader and invoke

  ./generate.py -s -c ../../tool/test/config/default_jobs_and_keys/config.json 
&lt;job&gt;

The config.json is such that all jobs listed with &#39;generate.py x&#39; are test 
jobs, and can be run as such.

These test jobs run in the nightly test suite, reports are on the Test Report 
Server.

[1] http://qooxdoo.org/documentation/1.0/tool/generator_default_jobs
[2] http://qooxdoo.org/documentation/1.0/tool/generator_config_ref</thetext>
          </long_desc>
          <long_desc isprivate="0">
            <commentid>35357</commentid>
            <who name="Martin Wittemann">martin.wittemann</who>
            <bug_when>2014-03-03 08:45:57 +0100</bug_when>
            <thetext>Move open issues to RESOLVED â€“ LATER, whose last comment is older than a year.</thetext>
          </long_desc>
      
      

    </bug>